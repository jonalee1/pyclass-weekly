{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# PyTorch quickstart for beginners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "This short introduction uses [PyTorch](https://pytorch.org/) to:\n",
        "\n",
        "1. Load a prebuilt dataset.\n",
        "1. Build a neural network machine learning model that classifies images.\n",
        "2. Train this neural network.\n",
        "3. Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize TensorBoard\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # First fully connected layer (input layer)\n",
        "        self.fc1 = nn.Linear(28*28, 512)  # 28*28 pixels input, 512 outputs\n",
        "        # Second fully connected layer (hidden layer)\n",
        "        self.fc2 = nn.Linear(512, 256)    # 512 inputs, 256 outputs\n",
        "        # Third fully connected layer (output layer)\n",
        "        self.fc3 = nn.Linear(256, 10)     # 256 inputs, 10 outputs (10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input tensor from [N, 1, 28, 28] to [N, 784] where\n",
        "        # N is the batch size, and 784 is the number of pixels in MNIST images.\n",
        "        x = x.view(-1, 28*28)\n",
        "        # Apply ReLU activation function after first and second layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # No activation function after the last layer as we'll use CrossEntropyLoss\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and normalize the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize images\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the network and optimizer\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()  # Clear the gradients of all optimized tensors\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = F.cross_entropy(output, target)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update parameters\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
        "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "            # Log to TensorBoard\n",
        "            writer.add_scalar('training loss', loss.item(), epoch * len(train_loader) + batch_idx)\n",
        "\n",
        "# Test function\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # No gradient computation for inference\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}'\n",
        "          f' ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
        "    # Log to TensorBoard\n",
        "    writer.add_scalar('test loss', test_loss, epoch)\n",
        "    writer.add_scalar('test accuracy', 100. * correct / len(test_loader.dataset), epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.321845\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.918873\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.483751\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.296660\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.323477\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.315379\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.323688\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.176637\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.402069\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.170228\n",
            "\n",
            "Test set: Average loss: 0.2719, Accuracy: 9238/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.166796\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.215550\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.501785\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.273661\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.140712\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.173882\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.209754\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.112197\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.079250\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.193996\n",
            "\n",
            "Test set: Average loss: 0.1919, Accuracy: 9445/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.212450\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.098038\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.270775\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.132348\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.139781\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.156816\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.136540\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.143261\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.153305\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.108216\n",
            "\n",
            "Test set: Average loss: 0.1458, Accuracy: 9580/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.044835\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.233495\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.221035\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.219510\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.182540\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.166178\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.165643\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.076374\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.131906\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.081572\n",
            "\n",
            "Test set: Average loss: 0.1319, Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.139565\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.097703\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.240678\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.058270\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.083910\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.086426\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.014467\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.054414\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.224781\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.161244\n",
            "\n",
            "Test set: Average loss: 0.1101, Accuracy: 9668/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.122378\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.024998\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.017294\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.053746\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.208421\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.025554\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.106648\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.162361\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.080500\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.068911\n",
            "\n",
            "Test set: Average loss: 0.0971, Accuracy: 9695/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.086485\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.091412\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.034327\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.099514\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.053644\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.060402\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.200334\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.125726\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.027804\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.059502\n",
            "\n",
            "Test set: Average loss: 0.0865, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.140110\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.022948\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.125580\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.077250\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.116055\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.020125\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.061745\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.091258\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.055871\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.189765\n",
            "\n",
            "Test set: Average loss: 0.0847, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.090687\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.048459\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.104165\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.032869\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.007103\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.023244\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.018326\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.074635\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.026716\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.047803\n",
            "\n",
            "Test set: Average loss: 0.0790, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.015903\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.012477\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.070010\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.116679\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.066787\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.098997\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.044097\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.021294\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.016016\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.033451\n",
            "\n",
            "Test set: Average loss: 0.0785, Accuracy: 9750/10000 (98%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Main training and testing loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(1, 11):  # Loop over the dataset multiple times (10 epochs)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "beginner.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
