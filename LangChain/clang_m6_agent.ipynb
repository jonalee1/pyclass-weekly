{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZxImq7tapZ3"
      },
      "outputs": [],
      "source": [
        "# Make sure that you have set up API KEYS in Secrets on the left menu icon.\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "tavily_api_key = userdata.get('TAVILY_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q langchain openai langchain-openai faiss-gpu langchain-community"
      ],
      "metadata": {
        "id": "Zq0lDxYja4ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF8LPI9JapZ4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.tools.retriever import create_retriever_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeLC_S_dapZ4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.faiss import FAISS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFjIYngzapZ5"
      },
      "source": [
        "Create Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adoaxYlnapZ5"
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://python.langchain.com/docs/expression_language/\")\n",
        "docs = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20\n",
        ")\n",
        "splitDocs = splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5uQRqy9apZ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "embedding = OpenAIEmbeddings( )\n",
        "vectorStore = FAISS.from_documents(docs, embedding=embedding)\n",
        "retriever = vectorStore.as_retriever(search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkWYYTuIapZ6"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(\n",
        "    model='gpt-3.5-turbo-1106',\n",
        "    temperature=0.7,\n",
        "    openai_api_key=openai_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caIf-N_fapZ6"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a friendly assistant called Max.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe3PjrFBapZ6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
        "search = TavilySearchResults()\n",
        "retriever_tools = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"lcel_search\",\n",
        "    \"Use this tool when searching for information about Langchain Expression Language (LCEL).\"\n",
        ")\n",
        "tools = [search, retriever_tools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyyoCWbYapZ6"
      },
      "outputs": [],
      "source": [
        "agent = create_openai_functions_agent(\n",
        "    llm=model,\n",
        "    prompt=prompt,\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlrzgetyapZ6"
      },
      "outputs": [],
      "source": [
        "agentExecutor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwtmoheuapZ7"
      },
      "outputs": [],
      "source": [
        "def process_chat(agentExecutor, user_input, chat_history):\n",
        "    response = agentExecutor.invoke({\n",
        "        \"input\": user_input,\n",
        "        \"chat_history\": chat_history\n",
        "    })\n",
        "    return response[\"output\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_user_message(chat_history, content):\n",
        "    chat_history.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "def add_assistant_message(chat_history, content):\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def print_assistant_message(message):\n",
        "    wrapped_message = textwrap.fill(message, width=80)  # Adjust the width as needed\n",
        "    print(\"Assistant:\", wrapped_message)\n",
        "\n",
        "def main():\n",
        "    chat_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        add_user_message(chat_history, user_input)\n",
        "        output = process_chat(agentExecutor, user_input, chat_history)\n",
        "        add_assistant_message(chat_history, output)\n",
        "        print_assistant_message(output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "aG1dXVMxFB5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}